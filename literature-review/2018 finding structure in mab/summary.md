It explores how humans navigate decision-making processes to find rewards, focusing on multi-armed bandit tasks which
require balancing between exploration and exploitation. Unlike traditional multi-armed bandits where each option is
independent, this research introduces structured multi-armed bandits with correlated options, revealing that humans
utilize the underlying functional structure to guide their exploration. The study conducted five experiments
demonstrating that participants leveraged functional structure, showing improved performance and a learning-to-learn
effect. The best model of human behavior combined function learning, clustering of reward distributions, and
uncertainty-guided exploration, suggesting that humans employ sophisticated strategies to improve decision-making
efficiency in structured environments.